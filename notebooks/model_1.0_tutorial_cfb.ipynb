{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "notebook_dir = os.getcwd()\n",
    "root_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "data_dir = os.path.join(root_dir, 'data')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import brier_score_loss, make_scorer, log_loss, mean_squared_error\n",
    "from IPython.display import display_html\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "from sklearn import calibration\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import GroupKFold, RandomizedSearchCV, cross_val_predict, GridSearchCV\n",
    "# from utils.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_df(df, anchor_df=None):\n",
    "    for col in df.columns:\n",
    "        data = df[col]\n",
    "        if anchor_df is None:\n",
    "            df[col] = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "        else:\n",
    "            df[col] = (data - np.min(anchor_df[col])) / (\n",
    "                np.max(anchor_df[col]) - np.min(anchor_df[col])\n",
    "            )\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_train_test_val_df(\n",
    "    df,\n",
    "    input_names,\n",
    "    output_name,\n",
    "    group_col=\"game_code\",\n",
    "    mask_test_season=2021,\n",
    "    mask_val_season=[2019, 2020],\n",
    "    normalize=False\n",
    "):\n",
    "    mask_train = ~(df.season.isin([mask_test_season] + mask_val_season))\n",
    "    mask_test = (df.season == mask_test_season)\n",
    "    mask_val = (df.season.isin(mask_val_season))\n",
    "    if normalize==False:\n",
    "        X_train = df.loc[mask_train, input_names]\n",
    "        X_test = df.loc[mask_test, input_names]\n",
    "        X_val = df.loc[mask_val, input_names]\n",
    "    else:\n",
    "        X_train = normalize_df(df.loc[mask_train, input_names])\n",
    "        X_test = normalize_df(df.loc[mask_test, input_names], df.loc[mask_train, input_names])\n",
    "        X_val = normalize_df(df.loc[mask_val, input_names], df.loc[mask_train, input_names])\n",
    "    y_train = df[mask_train][output_name]\n",
    "    group_train = df[mask_train][group_col]\n",
    "    y_test = df[mask_test][output_name]\n",
    "    group_test = df[mask_test][group_col]\n",
    "    y_val = df[mask_val][output_name]\n",
    "    group_val = df[mask_val][group_col]\n",
    "    return X_train, y_train, group_train, X_test, y_test, group_test, X_val, y_val, group_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1.0\n",
    "This notebook will act as an interactive tutorial for our Live Win Probability Model. This \"model\" is actual comprised of 3 separate models that \"stack\" on each other.\n",
    "1. Play and drive outcome models\n",
    "    * technically this is two separate models:\n",
    "        * Play outcome (first down, field goal made, field goal missed, touchdown, turnover, and none/other)\n",
    "            * only using the first down prediction from the output of this model\n",
    "        * Drive outcome (Clock, field goal made, field goal missed, punt, safety, touch down, turnover, turnover on downs)\n",
    "    * outputs for both models will be a series of probabilities for each class that all add up to 1\n",
    "2. End of regulation score differential model\n",
    "    * Dealing with overtime later, we want to predict how the score differential will change by the end of regulation.\n",
    "        * i.e., if the current score differential (home score - away score) is -3 and the end of regulation score differential is -10, the target value will be -7\n",
    "    * Output of this will be a series of probabilities from for all score differential possibilities from -35 to 35 (outputs <-35 or >35 will be set to -35/35 respectively)\n",
    "3. End of regulation score total model\n",
    "    * Similar concept to the score differential model\n",
    "    * Again, we're using the change in end of regulation score total as the target value\n",
    "    * Outputs will be a series of probabilites for classes from 0 to 83 (outputs will be capped at 83)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Let's take a look at the data that we are pulling from oracle\n",
    "* First we have event_df and odds_df\n",
    "* event_df is the play by play data mixed with some import game information\n",
    "* Odds data has vegas predictions for almost all the games in the set (missing games will be given the average vegas spread and over/under)\n",
    "    * The spread and over/under are merged with the event table to give us our pre-game priors\n",
    "    * some games have multiple odds so duplicates are removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = pd.read_parquet(os.path.join(data_dir, \"event_data_cfb.parquet\"))\n",
    "event_df = event_df.drop_duplicates([\"nevent\", \"game_code\"]).reset_index(drop=True)\n",
    "odds_df = pd.read_parquet(os.path.join(data_dir, \"odds_data_cfb.parquet\"))\n",
    "odds_df = odds_df.drop_duplicates(\"game_code\")\n",
    "event_df[[\"cur_spread\", \"cur_over_under\"]] = event_df.merge(odds_df, how=\"left\", on=\"game_code\")[[\"cur_spread\", \"cur_over_under\"]].fillna({\"cur_spread\": np.mean(odds_df[\"cur_spread\"]), \"cur_over_under\": np.mean(odds_df[\"cur_over_under\"])})\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "display_html(event_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding timeouts remaining for both teams and time left in game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df[\"half\"] = round((event_df[\"quarter\"] + 0.01) / 2)\n",
    "event_df[\"home_timeout\"] = np.where(((event_df[\"event_id\"]==57)&(event_df[\"home_team_has_ball\"]==1))|((event_df[\"event_id\"]==58)&(event_df[\"home_team_has_ball\"]==0)), 1, 0)\n",
    "event_df[\"away_timeout\"] = np.where(((event_df[\"event_id\"]==57)&(event_df[\"home_team_has_ball\"]==0))|((event_df[\"event_id\"]==58)&(event_df[\"home_team_has_ball\"]==1)), 1, 0)\n",
    "event_df[\"home_timeouts_remaining\"] = np.clip(3 - event_df.groupby([\"game_code\", \"half\"])[\"home_timeout\"].cumsum(), 0, 3)\n",
    "event_df[\"away_timeouts_remaining\"] = np.clip(3 - event_df.groupby([\"game_code\", \"half\"])[\"away_timeout\"].cumsum(), 0, 3)\n",
    "event_df[\"time_left_in_game\"] = np.where(event_df[\"quarter\"] <= 4, event_df[\"play_start_time\"] + (4 - event_df[\"quarter\"]) * 900, event_df[\"play_start_time\"])\n",
    "event_df[\"time_left_in_game\"] = event_df[\"time_left_in_game\"].fillna(event_df[\"time_left_in_game\"].shift(1))\n",
    "# event_df[\"time_elapsed\"] = 900 - event_df[\"play_start_time\"] + (event_df[\"quarter\"] - 1) * 900\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our PBP will have multiple rows for one play, so if there's a fumble then recovery by offense and a touchdown, \n",
    "* that could have 2-3 rows of data and the touchdown wouldn't show up as being apart of the original play \n",
    "    * plays would look like this: 1. Run, 2. Fumble, 3. Offense Recovers the ball (TD)\n",
    "* So what we've done here is ensure that plays that are \"continuation\" that end in a touchdown, give a TD=True for all of the plays in the sequence\n",
    "* After that is taken care of we can setup all of the labels for play and drive description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df[\"sequence\"] = event_df[\"continuation\"].groupby(event_df[\"continuation\"].eq(0).cumsum()).cumsum()\n",
    "event_df[\"play_start_id\"] = event_df[\"nevent\"] - event_df[\"sequence\"]\n",
    "\n",
    "turnover_ids = [9, 16]\n",
    "event_df[\"turnover\"] = np.where(event_df[\"event_id\"].isin(turnover_ids), 1, 0)\n",
    "event_df[\"touchdown_scored\"] = np.where(event_df[\"home_score_added\"]+event_df[\"away_score_added\"]>=6, 1, 0)\n",
    "event_df[\"fieldgoal_made\"] = np.where(event_df[\"home_score_added\"]+event_df[\"away_score_added\"]==3, 1, 0)\n",
    "\n",
    "play_outcome_aggregate =event_df[[\"game_code\", \"play_start_id\", \"turnover\", \"touchdown_scored\", \"fieldgoal_made\", \"first_down\"]].groupby([\"game_code\", \"play_start_id\"], as_index=False).sum()\n",
    "event_df[\"touchdown_in_play\"] = np.clip(event_df.merge(play_outcome_aggregate,on=[\"game_code\", \"play_start_id\"], how=\"left\")[\"touchdown_scored_y\"], 0, 1)\n",
    "event_df[\"turnover_in_play\"] = np.clip(event_df.merge(play_outcome_aggregate,on=[\"game_code\", \"play_start_id\"], how=\"left\")[\"turnover_y\"], 0, 1)\n",
    "event_df[\"field_goal_in_play\"] = np.clip(event_df.merge(play_outcome_aggregate,on=[\"game_code\", \"play_start_id\"], how=\"left\")[\"fieldgoal_made_y\"], 0, 1)\n",
    "event_df[\"first_down_in_play\"] = np.clip(event_df.merge(play_outcome_aggregate,on=[\"game_code\", \"play_start_id\"], how=\"left\")[\"first_down_y\"], 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "event_df[\"play_outcome\"] = (\n",
    "    np.where((event_df[\"turnover_in_play\"]==1), \"turnover\",\n",
    "    # (event_df[\"touchdown_in_play\"]==1)&(event_df[\"turnover_in_play\"]==1), \"defensive_touchdown\", \n",
    "    np.where((event_df[\"punt\"]==1), \"punt\",\n",
    "    np.where((event_df[\"field_goal_in_play\"]==1), \"field_goal_made\",\n",
    "    np.where((event_df[\"field_goal_attempt\"]==1)&(event_df[\"field_goal_in_play\"]==0), \"field_goal_missed\",\n",
    "    np.where((event_df[\"first_down_in_play\"]==1)&(event_df[\"touchdown_in_play\"]==0)&(event_df[\"turnover_in_play\"]==0)&(event_df[\"punt\"]==0), \"first_down\",\n",
    "    np.where((event_df[\"touchdown_in_play\"]==1)&(event_df[\"turnover_in_play\"]==0), \"offensive_touchdown\", \"none\"))))))\n",
    ")\n",
    "drive_description_matrix = {\n",
    "    7: \"punt\",\n",
    "    9: \"turnover\",\n",
    "    14: \"turnover\",\n",
    "    17: \"field_goal_made\",\n",
    "    18: \"punt\",\n",
    "    20: \"safety\",\n",
    "    35: \"field_goal_missed\",\n",
    "    36: \"field_goal_missed\",\n",
    "    37: \"touch_down\",\n",
    "    38: \"clock\",\n",
    "    39: \"clock\",\n",
    "    40: \"turnover_on_downs\",\n",
    "    42: \"field_goal_made\",\n",
    "    51: \"clock\",\n",
    "}\n",
    "event_df[\"drive_outcome_desc_basic\"] = event_df[\"drive_outcome_id\"].map(drive_description_matrix)\n",
    "\n",
    "# event_df[\"drive_outcome\"] = np.where(\n",
    "#     (event_df[\"touchdown_in_drive\"]==1)&(event_df[\"turnover_in_drive\"]==1), \"defensive_touchdown\", \n",
    "#     np.where((event_df[\"touchdown_in_drive\"]==1)&(event_df[\"turnover_in_drive\"]==0), \"offensive_touchdown\",\n",
    "#     np.where((event_df[\"field_goal_in_drive\"]==1), \"field_goal_made\",\n",
    "#     np.where((event_df[\"touchdown_in_drive\"]==0)&(event_df[\"turnover_in_drive\"]==1), \"turnover\", \"none\"\n",
    "# ))))\n",
    "game_end_of_regulation_total_score = event_df[event_df.overtime==0].groupby(\"game_code\", as_index=False).max()[[\"game_code\", \"home_start_score\", \"away_start_score\"]]\n",
    "game_end_of_regulation_total_score[\"end_of_regulation_score_total\"] = game_end_of_regulation_total_score[\"home_start_score\"] + game_end_of_regulation_total_score[\"away_start_score\"]\n",
    "# event_df[\"end_of_regulation_score_total_diff\"] = \n",
    "event_df[\"end_of_regulation_score_total_diff\"] = (\n",
    "    event_df.merge(game_end_of_regulation_total_score, on=\"game_code\")[\"end_of_regulation_score_total\"]\n",
    "    - (event_df[\"home_start_score\"] + event_df[\"away_start_score\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation\n",
    "* We need to do a little bit of data manipulation to get the values we need, but we don't want to \"overwrite\" the values in event_df so we'll make copy of it called model_df\n",
    "* time left in half is added\n",
    "* from_scrimmage is changed so that PATs and two point conversions are not included\n",
    "* down, ytg, and yd_from_goal are changed so that all non-scrimmage plays are changed to a default \"null\" value\n",
    "* home_team_has_ball is change so that when kickoffs occur, the team receiving is the one that is in possession of the ball\n",
    "\n",
    "### Data Subset\n",
    "* Removing continuation plays that we mentioned before, so that each snap has just one target\n",
    "* Remove plays where the down is equal to 0 \n",
    "* Remove plays from scrimmage that did not count (e.g., plays that were waved off by penalties)\n",
    "* scrimmage_plays_we_want is event_id of all the scrimmage plays that *aren't* timeouts, end of quarters, and the two minute warning.\n",
    "* Remove all NA values for the feature inputs and target\n",
    "* Remove all plays that are not from scrimmage\n",
    "* Remove all overtime plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = deepcopy(event_df)\n",
    "model_df[\"time_left_in_half\"] = event_df[\"time_left_in_game\"] - ((2 - event_df[\"half\"]) * 1800)\n",
    "model_df[\"from_scrimmage\"] = np.where(event_df[\"event_id\"].isin([22, 47, 52, 53, 54, 55, 56]), 0, event_df[\"from_scrimmage\"])\n",
    "model_df[\"down\"] = np.where(model_df[\"from_scrimmage\"] == 0, 0, event_df[\"down\"])\n",
    "model_df[\"ytg\"] = np.where(model_df[\"from_scrimmage\"] == 0, -1, event_df[\"ytg\"])\n",
    "model_df[\"yd_from_goal\"] = np.where(model_df[\"from_scrimmage\"] == 0, -1, event_df[\"yd_from_goal\"])\n",
    "model_df[\"home_team_has_ball\"] = np.where(event_df[\"event_id\"].isin([5]), 1 - event_df[\"home_team_has_ball\"], event_df[\"home_team_has_ball\"])\n",
    "scrimmage_plays_we_want = [1, 2, 3, 4, 7, 9, 14, 17, 18, 35]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_names = [\n",
    "    'time_left_in_half',\n",
    "    'half',\n",
    "    'current_score_diff',\n",
    "    'current_score_total',\n",
    "    'cur_spread',\n",
    "    'cur_over_under',\n",
    "    'home_timeouts_remaining',\n",
    "    'away_timeouts_remaining',\n",
    "    # 'punt',\n",
    "    # 'field_goal_attempt',\n",
    "    'ytg',\n",
    "    'yd_from_goal',\n",
    "    'down',\n",
    "    'home_team_has_ball',\n",
    "]\n",
    "output_name = \"play_outcome\"\n",
    "mask_model = (\n",
    "    (model_df.continuation==0)&\n",
    "    (model_df.down!=0)&\n",
    "    (model_df.play_counts==1)&\n",
    "    (model_df.event_id.isin(scrimmage_plays_we_want))&\n",
    "    (model_df[input_names+[output_name]].notna().all(axis=1))&\n",
    "    (model_df[\"from_scrimmage\"]==1)&\n",
    "    (model_df[\"overtime\"]==0)\n",
    ")\n",
    "X_train, y_train, group_train, X_test, y_test, group_test, X_val, y_val, group_val = create_train_test_val_df(model_df[mask_model], input_names, output_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what the input features and output features look like. \n",
    "\n",
    "Event Name and yards gained is included to help interpret what is going on. \n",
    "\n",
    "This is the first 2 drives of the first game in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[mask_model][input_names + [\"event_name\", \"yards_gained\", \"play_outcome\", \"drive_outcome_desc_basic\"]].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in the Models and Creating Play/Drive Predictions\n",
    "* ~~For this exercise we won't be training the models, just loading saved models and then using them to make predictions~~\n",
    "* Now we are going to train the models\n",
    "* In addition, each prediction will be split up between home and away. So if the home team has the ball the predictions for the away team play/drive outcomes are going to be set to 0\n",
    "\n",
    "\n",
    "Let's take a look at how the predictions look for our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=GroupKFold(n_splits=3)\n",
    "\n",
    "rf_grid = {\n",
    "    \"n_estimators\": np.linspace(start=50, stop=500, num=10, dtype=int),\n",
    "    \"max_features\": [\"auto\", \"sqrt\"],\n",
    "    \"max_depth\": np.linspace(5, 15, num=11, dtype=int),\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "log_loss_scorer = make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n",
    "rf_play_outcome_search_model = RandomForestClassifier(verbose=100, n_jobs=-1, random_state=1)\n",
    "search_rf_play_outcome = RandomizedSearchCV(rf_play_outcome_search_model, rf_grid, cv=cv,random_state=42,n_iter=10,n_jobs=1,verbose=100, scoring=log_loss_scorer)\n",
    "# rf_play_outcome_search_model = RandomForestClassifier(verbose=100, n_jobs=1, random_state=1)\n",
    "# search_rf_play_outcome = RandomizedSearchCV(rf_play_outcome_search_model, rf_grid, cv=cv,random_state=42,n_iter=10,n_jobs=-1,verbose=100, scoring=log_loss_scorer)\n",
    "search_rf_play_outcome.fit(X_train,y_train,groups=group_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = \"drive_outcome_desc_basic\"\n",
    "mask_model = (\n",
    "    (model_df.continuation==0)&\n",
    "    (model_df.down!=0)&\n",
    "    (model_df.play_counts==1)&\n",
    "    (model_df.event_id.isin(scrimmage_plays_we_want))&\n",
    "    (model_df[input_names+[output_name]].notna().all(axis=1))&\n",
    "    (model_df[\"from_scrimmage\"]==1)&\n",
    "    (model_df[\"overtime\"]==0)\n",
    ")\n",
    "\n",
    "X_train, y_train, group_train, X_test, y_test, group_test, X_val, y_val, group_val = create_train_test_val_df(model_df[mask_model], input_names, output_name)\n",
    "cv=GroupKFold(n_splits=3)\n",
    "\n",
    "log_loss_scorer = make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n",
    "rf_drive_outcome_search_model = RandomForestClassifier(verbose=100, n_jobs=-1, random_state=1)\n",
    "search_rf_drive_outcome = RandomizedSearchCV(rf_drive_outcome_search_model, rf_grid, cv=cv,random_state=42,n_iter=10,n_jobs=1,verbose=100, scoring=log_loss_scorer)\n",
    "search_rf_drive_outcome.fit(X_train,y_train,groups=group_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Predictions\n",
    "* We'll add in the plays that didn't count\n",
    "* The predictions are broken up by home/away team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_model_predict = (\n",
    "    (model_df.continuation==0)&\n",
    "    (model_df.down!=0)&\n",
    "    (model_df[input_names].notna().all(axis=1))&\n",
    "    (model_df[\"from_scrimmage\"]==1)&\n",
    "    (model_df[\"overtime\"]==0)\n",
    ")\n",
    "\n",
    "\n",
    "search_rf_play_class_names = [\"search_rf_play_\" + x for x in search_rf_play_outcome.classes_]\n",
    "search_rf_drive_class_names = [\"search_rf_drive_\" + x for x in search_rf_drive_outcome.classes_]\n",
    "model_df[search_rf_play_class_names] = pd.DataFrame(search_rf_play_outcome.predict_proba(model_df[mask_model_predict][input_names]), index=model_df[mask_model_predict].index)\n",
    "model_df[search_rf_play_class_names] = model_df[search_rf_play_class_names].fillna(0)\n",
    "model_df[search_rf_drive_class_names] = pd.DataFrame(search_rf_drive_outcome.predict_proba(model_df[mask_model_predict][input_names]), index=model_df[mask_model_predict].index)\n",
    "model_df[search_rf_drive_class_names] = model_df[search_rf_drive_class_names].fillna(0)\n",
    "\n",
    "search_rf_play_class_names_home = [x + \"_home\" for x in search_rf_play_class_names]\n",
    "search_rf_play_class_names_away = [x + \"_away\" for x in search_rf_play_class_names]\n",
    "search_rf_drive_class_names_home = [x + \"_home\" for x in search_rf_drive_class_names]\n",
    "search_rf_drive_class_names_away = [x + \"_away\" for x in search_rf_drive_class_names]\n",
    "model_df[search_rf_play_class_names_home] = model_df[search_rf_play_class_names].where(model_df.home_team_has_ball==1, 0)\n",
    "model_df[search_rf_play_class_names_away] = model_df[search_rf_play_class_names].where(model_df.home_team_has_ball==0, 0)\n",
    "model_df[search_rf_drive_class_names_home] = model_df[search_rf_drive_class_names].where(model_df.home_team_has_ball==1, 0)\n",
    "model_df[search_rf_drive_class_names_away] = model_df[search_rf_drive_class_names].where(model_df.home_team_has_ball==0, 0)\n",
    "display_html(model_df[mask_model][input_names + search_rf_play_class_names + search_rf_drive_class_names].head(15))\n",
    "# display_html(model_df[mask_model][input_names + search_rf_drive_class_names].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Difference Model\n",
    "* Using the same inputs and adding the outputs of the previous model, we will predict the score differential probablities\n",
    "* Since this model is an MLP model, we will normalize the inputs. (all features will be made so that the range is from 0 to 1)\n",
    "* In this model, continuation, null values, end of quarters, and overtime is removed.\n",
    "* NEW: spread and over/under are replaced by a weighted home and away vegas score prediction. The weight is based on time remaining normalized. So beginning of the game is the full score predictions, half time would be 0.5 * full score predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[\"away_vegas_score_pred\"] = np.clip(model_df[\"cur_over_under\"], 30, 80) * 0.5 + model_df[\"cur_spread\"] * 0.5\n",
    "model_df[\"home_vegas_score_pred\"] = np.clip(model_df[\"cur_over_under\"], 30, 80) * 0.5 - model_df[\"cur_spread\"] * 0.5\n",
    "model_df[\"away_vegas_score_pred_weighted\"] = model_df[\"away_vegas_score_pred\"] * (model_df[\"time_left_in_game\"] / 3600)\n",
    "model_df[\"home_vegas_score_pred_weighted\"] = model_df[\"home_vegas_score_pred\"] * (model_df[\"time_left_in_game\"] / 3600)\n",
    "model_df[\"point_after_play\"] = np.where(model_df[\"point_after_kick\"] + model_df[\"two_point_attempt\"]==1, 1, 0)\n",
    "\n",
    "\n",
    "# search_mlp_score_diff_clipped_rf_drive_preds = pickle.load(open(os.path.join(root_dir, \"models/search_mlp_score_diff_clipped_rf_drive_preds.p\"), 'rb'))\n",
    "# search_mlp_score_diff_clipped_rf_drive_preds = pickle.load(open(os.path.join(root_dir, \"models/search_mlp_score_diff_clipped_rf_drive_preds_vegas_adjusted.p\"), 'rb'))\n",
    "model_df[\"end_of_regulation_score_diff_change_clipped\"] = np.clip(model_df[\"end_of_regulation_score_diff_change\"], -50, 50)\n",
    "\n",
    "\n",
    "# input_names_score_diff_pred = [item for item in input_names if item not in [\"punt\", \"field_goal_attempt\"]] + [\"kick_off\", \"point_after_kick\", \"two_point_attempt\"] + [\"search_rf_play_first_down_home\", \"search_rf_play_first_down_away\"] + search_rf_drive_class_names_home[1:] + search_rf_drive_class_names_away[1:]\n",
    "\n",
    "input_names_score_diff_pred = [\n",
    "    'time_left_in_half',\n",
    "    'half',\n",
    "    'current_score_diff',\n",
    "    'current_score_total',\n",
    "    # 'home_vegas_score_pred_weighted',\n",
    "    # 'away_vegas_score_pred_weighted',\n",
    "    'cur_spread',\n",
    "    'cur_over_under',\n",
    "    'home_timeouts_remaining',\n",
    "    'away_timeouts_remaining',\n",
    "    'ytg',\n",
    "    'yd_from_goal',\n",
    "    'down',\n",
    "    'home_team_has_ball',\n",
    "    'kick_off',\n",
    "    'point_after_play',\n",
    "    'search_rf_play_first_down_home',\n",
    "    'search_rf_play_first_down_away',\n",
    "    'search_rf_drive_field_goal_made_home',\n",
    "    'search_rf_drive_field_goal_missed_home',\n",
    "    'search_rf_drive_punt_home',\n",
    "    'search_rf_drive_safety_home',\n",
    "    'search_rf_drive_touch_down_home',\n",
    "    'search_rf_drive_turnover_home',\n",
    "    'search_rf_drive_turnover_on_downs_home',\n",
    "    'search_rf_drive_field_goal_made_away',\n",
    "    'search_rf_drive_field_goal_missed_away',\n",
    "    'search_rf_drive_punt_away',\n",
    "    'search_rf_drive_safety_away',\n",
    "    'search_rf_drive_touch_down_away',\n",
    "    'search_rf_drive_turnover_away',\n",
    "    'search_rf_drive_turnover_on_downs_away'\n",
    "\n",
    "]\n",
    "output_name = \"end_of_regulation_score_diff_change_clipped\"\n",
    "\n",
    "mask_model_score_diff = (\n",
    "    (model_df.continuation==0)&\n",
    "    (model_df[input_names_score_diff_pred+[output_name]].notna().all(axis=1))&\n",
    "    ~(model_df.event_id.isin([12,57,58,13]))&\n",
    "    (model_df[\"overtime\"]==0)\n",
    ")\n",
    "X_train, y_train, group_train, X_test, y_test, group_test, X_val, y_val, group_val = create_train_test_val_df(model_df[mask_model_score_diff], input_names_score_diff_pred, output_name, normalize=True)\n",
    "mlp_grid = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (10,30,10),(100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "score_diff_change_list_clipped = list(model_df.end_of_regulation_score_diff_change_clipped.drop_duplicates().sort_values())\n",
    "\n",
    "log_loss_scorer_score_diff = make_scorer(log_loss, greater_is_better=False, needs_proba=True, labels=score_diff_change_list_clipped)\n",
    "mlp_score_diff_search_base = MLPClassifier(verbose=True, early_stopping=True, n_iter_no_change=5, random_state=1)\n",
    "search_mlp_score_diff_clipped_rf_drive_preds = GridSearchCV(mlp_score_diff_search_base, mlp_grid, cv=cv,n_jobs=-1,verbose=100, scoring=log_loss_scorer_score_diff)\n",
    "search_mlp_score_diff_clipped_rf_drive_preds.fit(X_train,y_train,groups=group_train)\n",
    "\n",
    "normalized_score_pred_df = normalize_df(model_df[mask_model_score_diff][input_names_score_diff_pred], model_df[mask_model_score_diff & (model_df.season<2020)][input_names_score_diff_pred])\n",
    "mlp_search_score_diff_clipped_rf_drive_preds_preds = pd.DataFrame(search_mlp_score_diff_clipped_rf_drive_preds.predict_proba(normalized_score_pred_df.values), index=model_df[mask_model_score_diff].index)\n",
    "score_diff_clipped_rf_drive_preds_matrix = pd.DataFrame(np.zeros(mlp_search_score_diff_clipped_rf_drive_preds_preds.shape), index=mlp_search_score_diff_clipped_rf_drive_preds_preds.index)\n",
    "score_diff_change_list_clipped = list(model_df.end_of_regulation_score_diff_change_clipped.drop_duplicates().sort_values())\n",
    "\n",
    "for column in score_diff_clipped_rf_drive_preds_matrix.columns:\n",
    "    score_diff_clipped_rf_drive_preds_matrix[column] = score_diff_change_list_clipped[column] + model_df[\"current_score_diff\"]\n",
    "\n",
    "model_df[\"xhome_win_mlp_search_clipped_rf_drive_preds\"] = np.sum(mlp_search_score_diff_clipped_rf_drive_preds_preds.T[score_diff_clipped_rf_drive_preds_matrix.T>0], axis=0)\n",
    "model_df[\"xovertime_mlp_search_clipped_rf_drive_preds\"] = np.sum(mlp_search_score_diff_clipped_rf_drive_preds_preds.T[score_diff_clipped_rf_drive_preds_matrix.T==0], axis=0)\n",
    "model_df[\"xaway_win_mlp_search_clipped_rf_drive_preds\"] = np.sum(mlp_search_score_diff_clipped_rf_drive_preds_preds.T[score_diff_clipped_rf_drive_preds_matrix.T<0], axis=0)\n",
    "model_df[\"xend_of_regulation_score_diff_mlp_search_clipped_rf_drive_preds\"] = np.sum(score_diff_clipped_rf_drive_preds_matrix * mlp_search_score_diff_clipped_rf_drive_preds_preds, axis=1)\n",
    "\n",
    "display_html(model_df[[\"xhome_win_mlp_search_clipped_rf_drive_preds\", \"xovertime_mlp_search_clipped_rf_drive_preds\", \"xaway_win_mlp_search_clipped_rf_drive_preds\"]].dropna())\n",
    "display_html(pd.DataFrame(mlp_search_score_diff_clipped_rf_drive_preds_preds.values, columns=score_diff_change_list_clipped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[mask_model_score_diff][input_names_score_diff_pred+ [\"continuation\", output_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[\"end_of_regulation_score_total_diff_clipped\"] = np.clip(model_df[\"end_of_regulation_score_total_diff\"], 0, 105)\n",
    "\n",
    "\n",
    "output_name = \"end_of_regulation_score_total_diff_clipped\"\n",
    "input_names_total_score_pred = list(search_mlp_score_diff_clipped_rf_drive_preds.feature_names_in_) + [\"xend_of_regulation_score_diff_mlp_search_clipped_rf_drive_preds\"]\n",
    "X_train, y_train, group_train, X_test, y_test, group_test, X_val, y_val, group_val = create_train_test_val_df(model_df[mask_model_score_diff], input_names_total_score_pred, output_name, normalize=True)\n",
    "\n",
    "\n",
    "mlp_total_score_search_base = MLPClassifier(verbose=True, early_stopping=True, n_iter_no_change=5, random_state=1)\n",
    "search_mlp_total_score = GridSearchCV(mlp_total_score_search_base, mlp_grid, cv=cv,n_jobs=-1,verbose=100, scoring=log_loss_scorer)\n",
    "search_mlp_total_score.fit(X_train,y_train,groups=group_train)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6c5c0c69c1e48657661a596cadc74240e1a54a645d9f5ac259274dfdfc1bdd8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
